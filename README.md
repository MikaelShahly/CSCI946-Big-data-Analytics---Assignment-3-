# CSCI946-Big-data-Analytics---Assignment-3-
The rapid growth of digital images and videos has made visual data analysis a core aspect of Big Data Analytics, requiring advanced algorithms for efficient processing. Deep learning models play a crucial role in extracting complex patterns from images, driving applications such as surveillance, autonomous vehicles, healthcare diagnostics, sentiment analysis, and security systems. This integration demands specialised expertise, robust computational resources, and hardware like GPUs or TPUs to handle large datasets effectively.
Pre-trained models have become increasingly popular as feature extractors, enabling faster development of solutions by minimising retraining efforts. ImageNet, introduced in 2009, has been a benchmark for image recognition, propelling advancements with competitive challenges. However, reliance on the original ImageNet validation set (referred to as Test Set 1) has raised concerns about overfitting, as models risk becoming too specialised to its 50,000 images. To address this, ImageNetV2 introduced new validation sets like MatchedFrequency, referred to as Test Set 2, offering a similar class distribution to evaluate generalisation more effectively.
While differences in performance across these test sets persist, Recht et al. (2019) found that high-performing models on Test Set 1 also perform well on Test Set 2, suggesting that image difficulty and dataset composition, rather than overfitting, drive performance variability. These findings highlight the need for more diverse benchmarks to accurately measure model generalisation across datasets.

Regarding the background of our project, the goal is to prove whether models trained on the ImageNet dataset (Test Set 1) generalise effectively to the ImageNetV2 dataset (Test Set 2). We hypothesise that performance discrepancies arise due to subtle differences in the datasets, such as image difficulty, rather than overfitting. This aligns with the findings of Recht et al. (2019), who suggest that while accuracy drops are observed between original and new datasets, they are driven more by dataset complexity than model adaptivity (Recht et al., 2019). 

